{"id":1317,"date":"2022-09-27T10:56:51","date_gmt":"2022-09-27T10:56:51","guid":{"rendered":"https:\/\/discojournal.com\/?p=1317"},"modified":"2022-10-01T08:09:37","modified_gmt":"2022-10-01T08:09:37","slug":"ai-myth-metaphor","status":"publish","type":"post","link":"https:\/\/discojournal.com\/2022\/09\/ai-myth-metaphor\/","title":{"rendered":"AI, Myth and Metaphor &#8211; Ben Potter"},"content":{"rendered":"<div class=\"taxonomy-category wp-block-post-terms\"><a href=\"https:\/\/discojournal.com\/category\/essay\/\" rel=\"tag\">ESSAY<\/a><span class=\"wp-block-post-terms__separator\">, <\/span><a href=\"https:\/\/discojournal.com\/category\/nascent-future\/\" rel=\"tag\">NASCENT FUTURE<\/a><\/div>\n\n\n<div class=\"wp-block-columns is-layout-flex wp-container-core-columns-is-layout-1 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\"><\/div>\n<\/div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>By: Ben Potter<\/strong><\/h3>\n\n\n\n<h1 class=\"wp-block-heading\"><strong>AI, Myth and Metaphor<\/strong><\/h1>\n\n\n\n<h2 class=\"wp-block-heading\"><strong>What&#8217;s the &#8216;Intelligence&#8217; in Artificial Intelligence?<\/strong><\/h2>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Keywords: artificial intelligence; GPT-3; myth; metaphor; communication<\/strong><\/h3>\n\n\n\n<div class=\"wp-block-columns is-layout-flex wp-container-core-columns-is-layout-2 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\"><\/div>\n<\/div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Introduction: Welcome to the Future<\/strong><\/h3>\n\n\n\n<figure class=\"wp-block-pullquote has-ast-global-color-6-color has-text-color\" style=\"font-size:15px\"><blockquote><p>What does the future of Artificial Intelligence look like? Firstly, we will have much more data available to us. We&#8217;ll have sensors of every sort, embedded in all kinds of things: clothing, appliances, buildings. They will be connected to the Internet and constantly transmitting information about themselves and their surroundings. This data will be analysed by machine learning algorithms which are getting increasingly sophisticated as they are fed more data. Another thing is that the machines will have a much better understanding of language. This means they&#8217;ll be able to communicate with us more effectively, and the devices will be &#8216;always listening&#8217;, so that when we speak or make gestures they can respond quickly. It&#8217;s already happening with smartphones. Our world will be much more responsive to our wishes, but also much more vulnerable. The Internet is a powerful tool, and it can magnify anything we do with it &#8211; good or bad.<\/p><\/blockquote><\/figure>\n\n\n\n<p style=\"font-size:15px\">Ok, full disclosure, I didn\u2019t write this introduction, an AI called Generative Pre-Trained Transformer-3 (GPT-3) did.<sup>[1]<\/sup> GPT-3 is at the crest of a new wave of \u2018AI\u2019 research which uses deep learning and natural language processing (NLP) to manipulate data about language with the aim of automating communication. There is an astonishing amount of hype and myth surrounding these new \u2018AI\u2019 with Google researcher Blake Lemoine calling Google\u2019s language model LaMDA \u2018sentient\u2019 and GPT-3 engineer Ilya Sutskever calling them \u2018slightly conscious\u2019.<sup>[2]<\/sup> This position is reflected in popular culture with films like <em>Ex Machina<\/em> (2014) and <em>Her<\/em> (2013) perpetuating ideas of machine consciousness. But something is amiss \u2013 we often equate machine intelligence with human intelligence, even though human understanding and computational prediction are radically different ways of perceiving. Why is this so? It is because of the imprecision and myth surrounding the metaphor of \u2018intelligence\u2019 as it has been used within the field of AI. As AI researcher Erik J. Larson argues, the myth is that we are on an inevitable path towards AI superintelligence capable of reaching and then surpassing human intelligence.<sup>[3]<\/sup> Corporations have exploited this intelligence conflation and transformed it into a marketing tool, and we, as consumers, have bought into the myth. Despite the fact there has been real progress in recent years with AI\u2019s capable of outperforming humans on narrowly defined tasks, dreams of artificial general intelligence (AGI) which resembles human intelligence are sorely misplaced.<\/p>\n\n\n\n<p style=\"font-size:15px\">What I will attempt to do in this article is unpack the myth to show how reality differs from the hype. Firstly, taking GPT-3 as a case study, I will look at machine learning algorithms\u2019 deficient understanding of language. AI research is a broad field and taking GPT-3 and other Large Language Models (LLMs) as my case study helps focus on a particular branch of AI research which has dealt with what has often been considered the defining trait of human intelligence: language. Secondly, I will critique the metaphor of \u2018intelligence\u2019 as it has come to be used in AI, showing how its usage contributes to the myth. Finally, I propose that, to counter this myth, we rethink the term \u2018artificial intelligence\u2019, in view of what we know about how these systems operate.<sup>[4]<\/sup><\/p>\n\n\n\n<div class=\"wp-block-columns is-layout-flex wp-container-core-columns-is-layout-3 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\"><\/div>\n\n\n\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\">\n<figure class=\"wp-block-image size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"640\" height=\"480\" src=\"http:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/Copy-of-giphy-2-1.gif\" alt=\"\" class=\"wp-image-1354\"\/><\/figure>\n<\/div>\n\n\n\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\"><\/div>\n<\/div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Calculating communication without understanding<\/strong><\/h3>\n\n\n\n<p style=\"font-size:15px\">Developed by the company OpenAI, GPT-3 can perform a huge variety of text-based tasks. Known as a \u2018transformer\u2019, it works by identifying patterns that appear in human-written language, using a huge training corpus of textual data, scraped from the internet (input), and turning this into reassembled text (output). Effectively it is a massively scaled-up version of the predictive text function we have on our phones. But what separates GPT-3 from other NLP systems is that after training it can execute this great variety of tasks without further fine-tuning. All that is required is a prompt to manipulate the model towards a specific task.<sup>[5]<\/sup> For example, to generate my introduction, I supplied the text: \u201cWhere will Artificial Intelligence be in 10 years?\u201d. GPT-3 can then work out the chances of one word following another by calculating its probability within this defined context. Once it has picked out these patterns, it can reconstruct them to simulate human written text related to the prompt. The reason it can do this so fluently relates to its size &#8211; GPT-3 is one of the most powerful large language models (LLMs) ever created, trained on nearly 1 trillion words and contains 175 billion parameters.<sup>[6]<\/sup>&nbsp;<\/p>\n\n\n\n<p style=\"font-size:15px\">The fluency attained by GPT-3 and similar models has convinced some within the field of AI research of a breakthrough in the search for artificial general intelligence (AGI). Indeed, OpenAI even have as their mission statement that they seek to \u201censure that artificial general intelligence benefits all of humanity\u201d.<sup>[7]<\/sup> AGI is the idea that machines can exhibit generalised human cognitive abilities such as reading, writing, understanding and even sentience. Attaining it would be a key milestone towards ideas of superintelligence and AI singularity popularised by futurists like Ray Kurzweil, whereby machines eclipse humans as the most intelligent beings on the planet.<sup>[8]<\/sup> This is the holy grail of the myth of AI but a deeper look at exactly how GPT-3 functions and the problems it has with basic reasoning will show how far away we are from this reality.<br><\/p>\n\n\n\n<p style=\"font-size:15px\">The single most important fact in grasping how LLMs like GPT-3 work is that, unlike humans, <em>they have no embodied and meaningful comprehension of the world and its relation to language.<\/em> GPT-3 is an \u2018autoregressive\u2019 model, which means that it predicts future values based on past ones. In other words, it uses historical data of past words to predict the likely sequence of future words. There is no doubt that this method can create realistic and original discourse that can be difficult to distinguish from human text. It is nevertheless an entirely different method of composing text to the one used by humans. This is because GPT-3 and similar models have no understanding of the words they produce, nor do they have any feeling for their meaning. As AI researchers Gary Marcus and Ernest Davis show, you cannot trust GPT-3 to answer questions about real-world situations. For example, ask it how you might get your dining room table through a door into another room and it might suggest that you \u201ccut the door in half and remove the top half\u201d.<sup>[9]<\/sup> And it is not only problems with basic reasoning but also with racist and offensive language.<sup>[10]<\/sup> This is because GPT-3 simply approximates the probability of one word following another<em>.<\/em> Its disembodied and calculative logic leaves it semantically blindfolded, unable to distinguish the logical from the absurd. It has no consciousness, no ethics, no morals, and no understanding of normativity. In short, these AI are nowhere near \u2018human-level\u2019 intelligence, despite what those who perpetuate the myth might say.&nbsp;<\/p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"http:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure1.png\" alt=\"\" class=\"wp-image-1320\" width=\"293\" height=\"330\" srcset=\"https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure1.png 586w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure1-266x300.png 266w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure1-21x24.png 21w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure1-32x36.png 32w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure1-43x48.png 43w\" sizes=\"auto, (max-width: 293px) 100vw, 293px\" \/><figcaption>Figure 1. An example of the PhilosopherAI GPT-3 interface restricting prompt generation on \u201cEthiopia\u201d as it seeks to prevent the system generating offensive content. Ben Potter, 2022. Credit: <a rel=\"noreferrer noopener\" href=\"https:\/\/www.philosopherai.com\" target=\"_blank\">https:\/\/www.philosopherai.com<\/a>.&nbsp;<em>&nbsp;<\/em><\/figcaption><\/figure>\n\n\n\n<p style=\"font-size:15px\">In highlighting the myth and its detachment from reality, I am not suggesting that GPT-3 and similar models are not valuable and impressive technologies but rather that these machines simulate human abilities without the understanding, empathy, and intelligence of humans. They are the property of the biggest corporations in the world who have a vested interest in making these machines profitable and may do so without thinking through the dangers to society. This is the key point to keep in mind when we think about how these technologies might be used as they break out into the mainstream.&nbsp;<\/p>\n\n\n\n<p style=\"font-size:15px\">So, what could this technology be used for? As we have seen, GPT-3 can be used to create text. This means that it can be used to make <a href=\"https:\/\/www.gwern.net\/GPT-3#literary-parodies\" target=\"_blank\" rel=\"noreferrer noopener\">weird surrealist fiction<\/a>, or perhaps usher in the age of <a rel=\"noreferrer noopener\" href=\"https:\/\/www.theguardian.com\/commentisfree\/2020\/sep\/08\/robot-wrote-this-article-gpt-3\" target=\"_blank\">robo-journalism<\/a>. It can be used to <a rel=\"noreferrer noopener\" href=\"https:\/\/www.wired.com\/story\/ai-latest-trick-writing-computer-code\/\" target=\"_blank\">create computer code<\/a>, to <a rel=\"noreferrer noopener\" href=\"https:\/\/www.technologyreview.com\/2020\/10\/08\/1009845\/a-gpt-3-bot-posted-comments-on-reddit-for-a-week-and-no-one-noticed\/\" target=\"_blank\">power social media bots<\/a>, and to <a rel=\"noreferrer noopener\" href=\"https:\/\/azure.microsoft.com\/en-us\/services\/cognitive-services\/openai-service\/#overview\" target=\"_blank\">carry out automated conversational tasks in commercial settings<\/a>. It could even be used to power conversational interfaces in the style of Siri or Alexa, thus redefining how we retrieve information on the internet. More recently, OpenAI released a 12 billion parameter version of GPT-3 called DALL-E, which has been trained on pictures, and which can generate hilarious original material (Figure 2).&nbsp; However, the dark side of such technology would be its use in the creation of realistic deepfakes, <a rel=\"noreferrer noopener\" href=\"https:\/\/openai.com\/dall-e-2\/\" target=\"_blank\">hence why OpenAI currently blurs human face generations<\/a>. What is certain is that the economic potential of GPT-3, and NLP AI more broadly, is massive, due to these systems\u2019 versatility and their apparent ability to communicate with us. They nevertheless do so without the fundamental quality of human intelligence, despite what their advocates might suggest.&nbsp;<\/p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"http:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure2.png\" alt=\"\" class=\"wp-image-1321\" width=\"590\" height=\"414\" srcset=\"https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure2.png 590w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure2-300x211.png 300w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure2-24x17.png 24w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure2-36x25.png 36w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure2-48x34.png 48w\" sizes=\"auto, (max-width: 590px) 100vw, 590px\" \/><figcaption>Figure 2. Dall-E generations of \u201cthe fabric of reality being ripped\u201d and &#8220;man yelling at a toast&#8221;. The first image shows how the GPT-3 engine completely misses the concepts of \u201cthe fabric of reality\u201d and \u201cripped\u201d. The second image shows how OpenAI blurs realistic face images to prevent this technology being used to create deepfakes. Ben Potter, 2022. Credit: <a rel=\"noreferrer noopener\" href=\"https:\/\/huggingface.co\/spaces\/dalle-mini\/dalle-mini\" target=\"_blank\">https:\/\/huggingface.co\/spaces\/dalle-mini\/dalle-mini<\/a>.&nbsp; <em>&nbsp;<\/em><br><\/figcaption><\/figure>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Putting the &#8216;Intelligence&#8217; in AI: the origins of the myth<\/strong><\/h3>\n\n\n\n<p style=\"font-size:15px\">The term \u2018Artificial Intelligence\u2019 was coined in 1955 by John McCarthy and consolidated a year later at the 1956 Dartmouth Conference which signposted the official founding of the field. \u2018AI\u2019 as it is colloquially known, is now <a href=\"https:\/\/www.europarl.europa.eu\/RegData\/etudes\/ATAG\/2021\/690024\/EPRS_ATA(2021)690024_EN.pdf\" target=\"_blank\" rel=\"noreferrer noopener\">an umbrella term for a diverse set of technologies<\/a>, the meaning of which is imprecise. Indeed, I would argue that applying the term \u2018intelligence\u2019 to models such as GPT-3 or LaMDA is ideological and obfuscating \u2013 it contributes to the myth as a poorly thought through metaphor conflating human intelligence with the statistical reasoning displayed by machines. To explain how we got here, we need to look more closely at the concept of \u2018intelligence\u2019 and exactly what it came to represent for the early field of AI.<\/p>\n\n\n\n<p style=\"font-size:15px\">In 1950, before the nascent field of AI had coalesced, Alan Turing proposed the \u2018Imitation Game\u2019. More commonly known today as the Turing test, the game seeks to assess machine intelligence and involves an anonymous text conversation between a human interrogator and two interlocutors: one human and one machine. The task of the interrogator is to determine which interlocutor is the machine.<sup>[11]<\/sup> Turing initially poses the question \u201cCan machines think?\u201d but sidesteps it because of difficulty in defining the terms \u2018machine\u2019 and \u2018think\u2019.<sup>[12]<\/sup> Instead, he focused on one specific aspect of human intelligence: communication. In doing so, Turing turned a question about whether machines possess the broad and situational understanding that defines human thinking into a task where machines and their programmers are concerned solely with using a set of calculated decisions to simulate linguistic textual communication. In this move, he placed human perception of machines at the centre of AI research. What mattered was not whether machines thought like humans but rather how convincing the machines were at <em>appearing <\/em>human. Thus, Turing radically narrowed the meaning of \u2018intelligence\u2019 within the embryonic field of AI, to focus on simulating communication.<sup>[13]<\/sup>&nbsp;<\/p>\n\n\n\n<p style=\"font-size:15px\">It was 14 years before a machine capable of even playing Turing\u2019s hypothetical game was invented, when Joseph Weizenbaum, an MIT computer scientist, created the first chatbot, ELIZA, in 1964. The program itself was relatively simple and worked through scripts. Each script, or program, corresponded to a human role. For example, the most famous ELIZA script, Doctor, simulated a therapist.<sup>[14]<\/sup> It worked by breaking down text, input by a human interlocutor, into its data structure, and searching for patterns within it. If a keyword was spotted, the text was reassembled as a response to the interlocutor; if no keyword was spotted, a generic response was sent.<sup>[15]<\/sup>&nbsp;<\/p>\n\n\n\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"550\" height=\"290\" src=\"http:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure3.png\" alt=\"\" class=\"wp-image-1322\" srcset=\"https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure3.png 550w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure3-300x158.png 300w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure3-24x13.png 24w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure3-36x19.png 36w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/DISCO_Figure3-48x25.png 48w\" sizes=\"auto, (max-width: 550px) 100vw, 550px\" \/><figcaption>Figure 3. Screenshot of my conversation with an ELIZA model running the Doctor script. It shows the generic responses and increasing incomprehensibility of the program when faced with complex answers. Ben Potter, 2022. Credit: <a rel=\"noreferrer noopener\" href=\"http:\/\/psych.fullerton.edu\/mbirnbaum\/psych101\/eliza.htm\" target=\"_blank\">http:\/\/psych.fullerton.edu\/mbirnbaum\/psych101\/eliza.htm<\/a>.<\/figcaption><\/figure>\n\n\n\n<p style=\"font-size:15px\">What was important for Weizenbaum was not that his machine <em>be<\/em> intelligent but that it <em>appear<\/em> intelligent. He was not seeking true human-like intelligence; neither was he attempting to build a machine capable of understanding language. What he focused on instead was how humans interpreted the machine\u2019s generated output, combining abstract mathematical reasoning with psychological deception.<sup>[16]<\/sup> This is why scripts such as \u2018doctor\u2019 are important. They frame, and to some degree control, humans\u2019 interpretation of computer-generated conversation. Weizenbaum\u2019s insight has had far-reaching consequences in the field of AI. Indeed, the tendency of humans to anthropomorphise machines is known today as the \u2018ELIZA effect\u2019. Blake Lemoine\u2019s claims of language model sentience with his assertion that \u201cI know a person when I talk to it\u201d is a classic example of this.<sup>[17]<\/sup> Weizenbaum was wary of such effects and warned against exploiting them; however, his early and prescient concerns went unheeded. The mere appearance of intelligence was consolidated as a vital tool in the development of AI and the myth of computers with human-like intelligence took hold.<\/p>\n\n\n\n<div class=\"wp-block-columns is-layout-flex wp-container-core-columns-is-layout-4 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\">\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"60\" height=\"60\" src=\"http:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/purplestar.gif\" alt=\"\" class=\"wp-image-1356\" srcset=\"https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/purplestar.gif 60w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/purplestar-24x24.gif 24w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/purplestar-36x36.gif 36w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/purplestar-48x48.gif 48w\" sizes=\"auto, (max-width: 60px) 100vw, 60px\" \/><\/figure>\n<\/div>\n\n\n\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\"><\/div>\n\n\n\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\">\n<figure class=\"wp-block-image aligncenter size-full\"><img loading=\"lazy\" decoding=\"async\" width=\"60\" height=\"60\" src=\"http:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/purplestar.gif\" alt=\"\" class=\"wp-image-1356\" srcset=\"https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/purplestar.gif 60w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/purplestar-24x24.gif 24w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/purplestar-36x36.gif 36w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/purplestar-48x48.gif 48w\" sizes=\"auto, (max-width: 60px) 100vw, 60px\" \/><\/figure>\n<\/div>\n<\/div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>The control behind communication<\/strong><\/h3>\n\n\n\n<p style=\"font-size:15px\">Computer programmers researching AI since Weizenbaum have deployed a range of techniques to manipulate human interaction with machines in ways that make us more inclined to view these autonomous machines as possessing human-like traits. These range from writing idiosyncratic behaviours into code to creating personalities for \u2018virtual assistants\u2019 like Siri and Alexa. So, if these machines are not intelligent and are rather engaging in a kind of simulated communication, the question we should be asking is: what power and control lies behind the myth of apparent intelligence?&nbsp;<\/p>\n\n\n\n<p style=\"font-size:15px\">Weizenbaum used the analogy of how some people believe what a fortune teller has to say about their future to describe how some people read more insight and understanding into his ELIZA program than is there. When thinking about future uses of today\u2019s LLMs, it is not a huge stretch to extend that analogy. Imagine a Siri or Alexa-type assistant powered by GPT-3. They would be like a fortune teller who has scores of data about the person having their fortune told &#8211; so much data that they can predict the types of things that you might search for. You could easily start to think that this assistant knows you better than yourself. Moreover, the assistant might present information from the internet to you in idiosyncratic ways, simulating quirky traits which give it a personality. You might start to trust it, form a friendship with it, fall in love with it. All the while, the more you have been communicating with the machine, the more it has been learning about you. It has been drawing on encoded ideas from human psychology to maintain an illusion of spontaneity and randomness, while also consolidating control within your interactions.<sup>[18]<\/sup>&nbsp;<\/p>\n\n\n\n<p style=\"font-size:15px\">What is happening with the deployment of communicative AI is that the complex systems which administer and shape ever more of our lives are being placed behind another layer of ideological chicanery. We need to ask if we trust the likes of Google, Amazon, Apple, Meta and Microsoft to influence our lives in increasingly intimate ways with systems which they describe as \u2018intelligent\u2019 and which in reality are anything but. We need to ask why they want machines to appear humane, spontaneous and creative all whilst being strictly controlled.&nbsp; As Erik J. Larson suggests, AI produced by Big Tech will inevitably follow the logic of profit and scalability and forsake potentially fruitful avenues of future research, which could go some way toward creating a machine with the capacity to understand language as humans do.<sup>[19]<\/sup> Moreover, the race towards profitability \u2013 evidenced by OpenAI\u2019s change from \u2018not for profit\u2019 to \u2018capped profit\u2019<sup>[20]<\/sup> \u2013 will mean one thing: these systems will be rushed into public use before we have a chance to fully comprehend the effect they will have on our societies. These new forms of interaction will be no different underneath the hood. But they will feel friendlier and more trustworthy, and that is something we should be wary of.&nbsp;<\/p>\n\n\n\n<div class=\"wp-block-columns is-layout-flex wp-container-core-columns-is-layout-5 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\"><\/div>\n\n\n\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\">\n<figure class=\"wp-block-image aligncenter size-full is-resized\"><img loading=\"lazy\" decoding=\"async\" src=\"http:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/017.gif\" alt=\"\" class=\"wp-image-1358\" width=\"123\" height=\"100\" srcset=\"https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/017.gif 37w, https:\/\/discojournal.com\/wp-content\/uploads\/2022\/09\/017-24x19.gif 24w\" sizes=\"auto, (max-width: 123px) 100vw, 123px\" \/><figcaption><em>almost done!<\/em><\/figcaption><\/figure>\n<\/div>\n\n\n\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\"><\/div>\n<\/div>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>Beyond the myth: reimagining the &#8216;Intelligence&#8217; metaphor<\/strong><\/h3>\n\n\n\n<p style=\"font-size:15px\">As recently noted by the European Parliamentary Research Service, &#8220;the term \u2018AI\u2019 relies upon a metaphor for the human quality of intelligence\u201d.<sup>[21]<\/sup> What I have tried to do in this article is show how the intelligence metaphor is inaccurate and thus contributes to the myth of AI. The metaphors that we use to describe things shape how we perceive and think about concepts and objects in the world.<sup>[22]<\/sup> This is why reconsidering the metaphor \u2018Artificial Intelligence\u2019 is so important. The view of these systems as \u2018intelligent\u2019, as I have shown, dates back over 70 years. In this time, the idea of machine intelligence has captured public imagination and laid the ideological groundwork for the widespread and unthinking reception of various technologies which pose as intelligent. The technologies that fall under the AI umbrella are diverse. They carry out a huge array of tasks, many of which are essential to society\u2019s function. Moreover, they often offer insights that cannot be achieved by humans alone. Therefore, the narrow and controlled application of machine learning algorithms to problem-solving scenarios is something to be admired and pursued. However, as I have highlighted, the economic potential of systems such as GPT-3 means that they will inevitably be rolled out across multiple sectors, coming to control and influence more aspects of our lives. One way of remaining alert to these developments is to reimagine the metaphors we use to describe the technologies which power them.<\/p>\n\n\n\n<p style=\"font-size:15px\">But what would be a more suitable names for these systems? Two descriptions that more accurately represent what LLMs do are \u2018human task simulation\u2019 and \u2018artificial communication\u2019.<sup>[23]<\/sup> These terms reflect the fact that programmers behind LLMs have consciously or unconsciously abandoned the search for human-like \u2018intelligence\u2019 in favour of systems which can successfully simulate human communication and other tasks.<sup>[24]<\/sup> These metaphors help us understand, and think critically about, the workings of the systems that they describe. For example, the word \u2018simulated\u2019 is associated not only with computing and imitations but also with deception. \u2018Communication\u2019 points to the specific aspect of human intelligence which is attempting to be simulated. It is a narrow and precise term, unlike the vaguer \u2018intelligence\u2019. One of the core features of language is that it helps us orientate ourselves in the world, come to mutual understandings with others, and create shared focal points for the meaningful issues within society.<sup>[25]<\/sup> &nbsp;If we are to retain perspective on these systems and avoid getting sucked into the AI myth, then avoiding the \u2018intelligence\u2019 metaphor and the appropriation of human cognitive abilities that this entails is not a bad place to start.<\/p>\n\n\n\n<p>[end]<\/p>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>BIO<\/strong><\/h3>\n\n\n\n<p style=\"font-size:15px\"><strong>Ben Potter <\/strong>is a PhD researcher at the University of Sussex researching the social and political effects of artificial intelligence. Specifically, his interest is in how communicative AI technologies such as Siri, Alexa or GPT-3 are changing the structural mediations within what has been termed the \u2018public sphere\u2019, including how we communicate on and retrieve information form the internet. He is interested in the policy implications and ethical regulation of AI and writes on the philosophical and sociological effects of technology more broadly.<\/p>\n\n\n\n<h3 class=\"wp-block-heading\"><strong>REFERENCES<\/strong><\/h3>\n\n\n\n<p><sup>[1] <\/sup>To generate this introduction, I provided the GPT-3 powered interface \u2018philosopherAI\u2019 with the prompt: \u201cwhere will Artificial Intelligence be in 10 years?\u201d. For clarification, the GPT-3 generated text starts with \u201cwe will have much more data\u201d and ends with \u201cand it can magnify anything we do with it \u2013 good or bad\u201d. I removed two paragraphs for concision but left the rest of the text unaltered. You can try out your own queries at <a href=\"https:\/\/www.philosopherai.com\">https:\/\/www.philosopherai.com<\/a>.&nbsp;<\/p>\n\n\n\n<p><sup>[2]<\/sup> Blake Lemoine, \u2018Is LaMDA Sentient? \u2013 An Interview\u2019 accessed on 18<sup>th<\/sup> June 2022 at: <a href=\"https:\/\/cajundiscordian.medium.com\/is-lamda-sentient-an-interview-ea64d916d917\">https:\/\/cajundiscordian.medium.com\/is-lamda-sentient-an-interview-ea64d916d917<\/a>; And Ilya Sutskver\u2019s twitter comments at: <a href=\"https:\/\/twitter.com\/ilyasut\/status\/1491554478243258368?s=21&amp;t=noC6T4yt85xNtfVYN8DsmQ\">https:\/\/twitter.com\/ilyasut\/status\/1491554478243258368?s=21&amp;t=noC6T4yt85xNtfVYN8DsmQ<\/a>.<\/p>\n\n\n\n<p><sup>[3]<\/sup> Erik J. Larson, <em>The Myth of Artificial Intelligence: Why Computers Can\u2019t Think the Way We Do <\/em>(Cambridge: The Belknap Press, 2021), 1.<\/p>\n\n\n\n<p><sup>[4] <\/sup>This article is drawing on research from my wider PhD project which is enquiring into the way artificial intelligence creates discourse out of data. I aim to publish a full-length research article on natural language processing artificial intelligence in 2023 which will include preliminary work conducted here on GPT-3.<\/p>\n\n\n\n<p><sup>[5] <\/sup>Pengfei Liu,&nbsp;Weizhe Yuan,&nbsp;Jinlan Fu, et al., \u2018Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing\u2019, p. 3. Visited 17<sup>th<\/sup> June 2022, <a href=\"https:\/\/arxiv.org\/pdf\/2107.13586.pdf\">https:\/\/arxiv.org\/pdf\/2107.13586.pdf<\/a>.<\/p>\n\n\n\n<p><sup>[6] <\/sup>Parameters are the adjustable \u2018weights\u2019 which inform the value of a specific input into the end result. For the technical paper from OpenAI showing how GPT-3 was trained, see T. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal et al., \u2018Language models are few-shot learners\u2019, <em>OpenAI<\/em>, p. 8. Visited 10<sup>th<\/sup> June 2022, <a href=\"https:\/\/arxiv.org\/pdf\/2005.14165.pdf\">https:\/\/arxiv.org\/pdf\/2005.14165.pdf<\/a>.<\/p>\n\n\n\n<p><sup>[7]<\/sup> <a href=\"https:\/\/openai.com\/about\/\">https:\/\/openai.com\/about\/<\/a>.<\/p>\n\n\n\n<p><sup>[8] <\/sup>Ray Kurzweil, <em>The Singularity is Near: When Humans Transcend Biology <\/em>(New York: Penguin, 2005).<\/p>\n\n\n\n<p><sup>[9] <\/sup>Gary Marcus and Ernest Davis, \u2018GPT-3, Bloviator: OpenAI\u2019s language generator has no idea what it\u2019s talking about\u2019, <em>MIT Technology Review, <\/em>August 2020. Visited 17<sup>th<\/sup> June 2022, <a href=\"https:\/\/www.technologyreview.com\/2020\/08\/22\/1007539\/gpt3-openai-language-generator-artificial-intelligence-ai-opinion\/\">https:\/\/www.technologyreview.com\/2020\/08\/22\/1007539\/gpt3-openai-language-generator-artificial-intelligence-ai-opinion\/<\/a><strong>.<\/strong><\/p>\n\n\n\n<p><sup>[10]<\/sup> Emily M. Bender, Timnit Gebru, Angelina McMillan-Major, Shmargaret Shmitchell et al., \u2018On the Dangers of Stochastic Parrots: Can Language Models be too Big?\u2019 <em>FAccT &#8217;21: Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency<\/em>, 2021. At <a href=\"https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3442188.3445922\">https:\/\/dl.acm.org\/doi\/pdf\/10.1145\/3442188.3445922<\/a>. For an example of a GPT-3 powered interface creating racist text see: <a href=\"https:\/\/twitter.com\/abebab\/status\/1309137018404958215?lang=en\">https:\/\/twitter.com\/abebab\/status\/1309137018404958215?lang=en<\/a>.&nbsp; This something that OpenAI are aware of, restricting the generation of certain content and adding a layer of human fine tuning to prevent GPT-3 creating racist discourse. To see how they achieve this, see Long Ouyang, Jeff Wu, Xu Jiang et al., \u2018Training Language Models to Follow Instructions with Human Feedback\u2019, <em>OpenAI<\/em>, 2022:<em> <\/em><a href=\"https:\/\/arxiv.org\/pdf\/2203.02155.pdf\">https:\/\/arxiv.org\/pdf\/2203.02155.pdf<\/a>. The process of adding a human layer of supervision within these systems is called \u2018reinforcement learning from human feedback\u2019 (RLHF) and makes GPT-3 somewhat safer and commercially viable but less autonomous.<\/p>\n\n\n\n<p><sup>[11]<\/sup> Alan Turing, \u201cComputing Machinery and Intelligence\u201d.&nbsp;<em>Mind,&nbsp;<\/em>59 (236), 1950: 443.<\/p>\n\n\n\n<p><sup>[12] <\/sup>Turing, \u2018Computing Machinery and Intelligence\u2019, 433. To date, no AI has ever passed the Turing test. Those that have come closest have used deception to trick the human interlocutors.<\/p>\n\n\n\n<p><sup>[13] <\/sup>Larson, <em>The Myth of Artificial Intelligence<\/em>, 10.<\/p>\n\n\n\n<p><sup>[14] <\/sup>If you want to have a play at interacting with an ELIZA replica you can do so at: <a href=\"http:\/\/psych.fullerton.edu\/mbirnbaum\/psych101\/eliza.htm\">http:\/\/psych.fullerton.edu\/mbirnbaum\/psych101\/eliza.htm<\/a>.<\/p>\n\n\n\n<p><sup>[15]<\/sup> Joseph Weizenbaum, \u201cContextual Understanding by Computers\u201d, <em>Communications of the ACM <\/em>(Volume: 10 Number: 8, August 1967), 475.<\/p>\n\n\n\n<p><sup>[16] <\/sup>Simone Natale, <em>Deceitful Media: Artificial Intelligence and Social Life after the Turing Test <\/em>(Oxford: Oxford University Press, 2021), 53.<\/p>\n\n\n\n<p><sup>[17]<\/sup> Blake Lemoine, \u2018Is LaMDA Sentient? \u2013 An Interview\u2019.<\/p>\n\n\n\n<p><sup>[18] <\/sup>Natale, 120; and Esposito, 10.<\/p>\n\n\n\n<p><sup>[19] <\/sup>Erik J. Larson, <em>The Myth of Artificial Intelligence, <\/em>272.<\/p>\n\n\n\n<p><sup>[20] <\/sup>Alberto Romero, \u2018How OpenAI Sold its Soul for $1 Billion\u2019, accessed on 24<sup>th<\/sup> Aug 2022 at <a href=\"https:\/\/onezero.medium.com\/openai-sold-its-soul-for-1-billion-cf35ff9e8cd4\">https:\/\/onezero.medium.com\/openai-sold-its-soul-for-1-billion-cf35ff9e8cd4<\/a>.<\/p>\n\n\n\n<p><sup>[21]<\/sup> European Parliamentary Research Service, \u2018What if we chose new metaphors for artificial intelligence?\u2019 accessed on 24 Aug 2022 at&nbsp; <a href=\"https:\/\/www.europarl.europa.eu\/RegData\/etudes\/ATAG\/2021\/690024\/EPRS_ATA(2021)690024_EN.pdf\">https:\/\/www.europarl.europa.eu\/RegData\/etudes\/ATAG\/2021\/690024\/EPRS_ATA(2021)690024_EN.pdf<\/a>.<\/p>\n\n\n\n<p><sup>[22] <\/sup>George Lakoff and Mark Johnson, <em>The Metaphors We Live By <\/em>(Chicago: University of Chicago Press, 2003).<\/p>\n\n\n\n<p><sup>[23] <\/sup>Elena Esposito, <em>Artificial Communication: How Algorithms Produce Social Intelligence <\/em>(Cambridge: The MIT Press, 2022), 5.<\/p>\n\n\n\n<p><sup>[24]<\/sup> Ibid.<\/p>\n\n\n\n<p><sup>[25] <\/sup>Morten H. Christiansen and Nick Charter, <em>The Language Game: How Improvisation Created Language and Changed the World <\/em>(London: Bantam Press, 2022), 15-23.<\/p>\n\n\n\n<div class=\"wp-block-columns is-layout-flex wp-container-core-columns-is-layout-6 wp-block-columns-is-layout-flex\">\n<div class=\"wp-block-column is-layout-flow wp-block-column-is-layout-flow\" style=\"flex-basis:100%\">\n<div class=\"wp-block-group is-layout-flow wp-block-group-is-layout-flow\"><div class=\"wp-block-group__inner-container\">\n<div style=\"height:100px\" aria-hidden=\"true\" class=\"wp-block-spacer\"><\/div>\n\n\n\n<h2 class=\"wp-block-heading has-text-align-center\"><a href=\"http:\/\/discojournal.com\/issue-2\/\" data-type=\"link\" data-id=\"http:\/\/discojournal.com\/issue-2\/\">\ud83e\udea9 <\/a><a href=\"http:\/\/discojournal.com\/issue-2\/\">back to the ball<\/a><a href=\"http:\/\/discojournal.com\/homepage-test\/\" data-type=\"page\" data-id=\"228\"> <\/a><a href=\"http:\/\/discojournal.com\/issue-2\/\">\ud83e\udea9<\/a><\/h2>\n<\/div><\/div>\n<\/div>\n<\/div>\n\n\n\n<p><\/p>\n\n\n\n<p><\/p>\n\n\n\n<p><\/p>\n","protected":false},"excerpt":{"rendered":"<p>By: Ben Potter AI, Myth and Metaphor What&#8217;s the &#8216;Intelligence&#8217; in Artificial Intelligence? Keywords: artificial intelligence; GPT-3; myth; metaphor; communication Introduction: Welcome to the Future What does the future of Artificial Intelligence look like? Firstly, we will have much more data available to us. We&#8217;ll have sensors of every sort, embedded in all kinds of [&hellip;]<\/p>\n","protected":false},"author":1,"featured_media":0,"comment_status":"closed","ping_status":"open","sticky":false,"template":"","format":"standard","meta":{"_coblocks_attr":"","_coblocks_dimensions":"","_coblocks_responsive_height":"","_coblocks_accordion_ie_support":"","site-sidebar-layout":"default","site-content-layout":"","ast-site-content-layout":"","site-content-style":"default","site-sidebar-style":"default","ast-global-header-display":"","ast-banner-title-visibility":"","ast-main-header-display":"","ast-hfb-above-header-display":"","ast-hfb-below-header-display":"","ast-hfb-mobile-header-display":"","site-post-title":"","ast-breadcrumbs-content":"","ast-featured-img":"","footer-sml-layout":"","theme-transparent-header-meta":"","adv-header-id-meta":"","stick-header-meta":"","header-above-stick-meta":"","header-main-stick-meta":"","header-below-stick-meta":"","astra-migrate-meta-layouts":"default","ast-page-background-enabled":"default","ast-page-background-meta":{"desktop":{"background-color":"var(--ast-global-color-4)","background-image":"","background-repeat":"repeat","background-position":"center center","background-size":"auto","background-attachment":"scroll","background-type":"","background-media":"","overlay-type":"","overlay-color":"","overlay-opacity":"","overlay-gradient":""},"tablet":{"background-color":"","background-image":"","background-repeat":"repeat","background-position":"center center","background-size":"auto","background-attachment":"scroll","background-type":"","background-media":"","overlay-type":"","overlay-color":"","overlay-opacity":"","overlay-gradient":""},"mobile":{"background-color":"","background-image":"","background-repeat":"repeat","background-position":"center center","background-size":"auto","background-attachment":"scroll","background-type":"","background-media":"","overlay-type":"","overlay-color":"","overlay-opacity":"","overlay-gradient":""}},"ast-content-background-meta":{"desktop":{"background-color":"var(--ast-global-color-5)","background-image":"","background-repeat":"repeat","background-position":"center center","background-size":"auto","background-attachment":"scroll","background-type":"","background-media":"","overlay-type":"","overlay-color":"","overlay-opacity":"","overlay-gradient":""},"tablet":{"background-color":"var(--ast-global-color-5)","background-image":"","background-repeat":"repeat","background-position":"center center","background-size":"auto","background-attachment":"scroll","background-type":"","background-media":"","overlay-type":"","overlay-color":"","overlay-opacity":"","overlay-gradient":""},"mobile":{"background-color":"var(--ast-global-color-5)","background-image":"","background-repeat":"repeat","background-position":"center center","background-size":"auto","background-attachment":"scroll","background-type":"","background-media":"","overlay-type":"","overlay-color":"","overlay-opacity":"","overlay-gradient":""}},"footnotes":""},"categories":[11,16],"tags":[],"class_list":["post-1317","post","type-post","status-publish","format-standard","hentry","category-essay","category-nascent-future"],"_links":{"self":[{"href":"https:\/\/discojournal.com\/wp-json\/wp\/v2\/posts\/1317","targetHints":{"allow":["GET"]}}],"collection":[{"href":"https:\/\/discojournal.com\/wp-json\/wp\/v2\/posts"}],"about":[{"href":"https:\/\/discojournal.com\/wp-json\/wp\/v2\/types\/post"}],"author":[{"embeddable":true,"href":"https:\/\/discojournal.com\/wp-json\/wp\/v2\/users\/1"}],"replies":[{"embeddable":true,"href":"https:\/\/discojournal.com\/wp-json\/wp\/v2\/comments?post=1317"}],"version-history":[{"count":30,"href":"https:\/\/discojournal.com\/wp-json\/wp\/v2\/posts\/1317\/revisions"}],"predecessor-version":[{"id":2083,"href":"https:\/\/discojournal.com\/wp-json\/wp\/v2\/posts\/1317\/revisions\/2083"}],"wp:attachment":[{"href":"https:\/\/discojournal.com\/wp-json\/wp\/v2\/media?parent=1317"}],"wp:term":[{"taxonomy":"category","embeddable":true,"href":"https:\/\/discojournal.com\/wp-json\/wp\/v2\/categories?post=1317"},{"taxonomy":"post_tag","embeddable":true,"href":"https:\/\/discojournal.com\/wp-json\/wp\/v2\/tags?post=1317"}],"curies":[{"name":"wp","href":"https:\/\/api.w.org\/{rel}","templated":true}]}}